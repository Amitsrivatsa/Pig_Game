-------------------------------------------------------------Data-Ingestion------------------------------------------------------------

---------------------------------------------------------------Cassandra---------------------------------------------------------------

1.Create a cassandra database named "GoShopping" and use it further.

Ans: 
create keyspace GoShopping with replication =
{ 'class': 'SimpleStrategy', 'replication_factor': 1 };


2.Create a cassandra table named "UserIpDetails" and load the data from GoShopping_IpLookup.txt file.

Ans:
create table goshopping.UserIpDetails (IP text,Country text,State text,City text,ApproxLat text,ApproxLng text,primary key(IP,Country));

copy UserIpDetails(IP,Country,State,City,ApproxLat,ApproxLng) from '/home/vagrant/goShopping_IpLookup.txt';

----------------------------------------------------------------HDFS--------------------------------------------------------------------

1. hdfs dfs -mkdir /GoShopping;

2. hdfs dfs -put /home/vagrant/goShopping_IpLookup.txt /GoShopping;

-------------------------------------------------------Streaming source to Kafka---------------------------------------------------------

1. bin/kafka-topic.sh --create --zookeeper master:2181 --replication-factor 1 --partition 1 --topic goshopping_webclicks

2. nc -n 127.0.0.1 -l 9999 | bin/kafka-console-producer.sh --broker-list localhost:9092 --topic goshopping_webclicks

-------------------------------------------------------------Kafka to HDFS---------------------------------------------------------------

1. hdfs dfs -mkdir /GoShopping/GoShopping_WebClicks 

2. 
import org.apache.spark._
import org.apache.spark.streaming._
//import org.apache.spark.streaming.StreamingContext._ // not necessary since Spark 1.3

object Prog1{
  def main(args: Array[String]) {
	val conf = new SparkConf().setMaster("local[2]").setAppName("Prog1")
	val ssc = new StreamingContext(conf, Seconds(20))
	val lines = ssc.socketTextStream("127.0.0.1", 9999)
	lines.saveAsTextFiles("/Project")
ssc.start()
ssc.awaitTermination()
}
}


spark-submit --class Prog1 target/scala-2.10/streaming-word-count-1_2.10-1.0.jar